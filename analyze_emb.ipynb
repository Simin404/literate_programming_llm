{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "from prediction import analyze_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "(30303, 4) (17669, 4)\n"
     ]
    }
   ],
   "source": [
    "device = utils.getting_device()\n",
    "\n",
    "train_df =pd.read_csv('data/train_30303.csv')\n",
    "test_df = pd.read_csv('data/test_17669.csv')\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base: BERT, GPT, CodeBERT, RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/bert_30303.pt\n",
      "Model vertified: BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extract embeddings......\n",
      "Time elapsed: 3140.53 seconds, Data processed:10000\n",
      "Time elapsed: 3910.11 seconds, Data processed:20000\n",
      "Time elapsed: 8006.41 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/bert_17669.pt\n",
      "Model vertified: BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extract embeddings......\n",
      "Time elapsed: 9117.45 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.48 seconds, Data predicted: 0\n",
      "Time elapsed: 238.36 seconds, Data predicted: 5000\n",
      "Time elapsed: 239.84 seconds, Data predicted: 10000\n",
      "Time elapsed: 238.78 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 52.06%\n",
      "Accuracy of Programming Task prediction: 16.10%\n"
     ]
    }
   ],
   "source": [
    "model = 'bert'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/gpt_30303.pt\n",
      "Model vertified: GPT\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 3979.21 seconds, Data processed:10000\n",
      "Time elapsed: 4906.47 seconds, Data processed:20000\n",
      "Time elapsed: 5774.42 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/gpt_17669.pt\n",
      "Model vertified: GPT\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 5598.58 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.63 seconds, Data predicted: 0\n",
      "Time elapsed: 242.26 seconds, Data predicted: 5000\n",
      "Time elapsed: 244.55 seconds, Data predicted: 10000\n",
      "Time elapsed: 241.90 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 39.60%\n",
      "Accuracy of Programming Task prediction: 6.54%\n"
     ]
    }
   ],
   "source": [
    "model = 'gpt'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/codegpt_30303.pt\n",
      "Model vertified: CodeGPT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8442885e85c541339cbbee985d806c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dbbfb2754a45bc9561a2f61e9871ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134d57d76f5a4b49905e1c10b8380a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading added_tokens.json:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2440cd54bfc24795b5ea7bdfe99a7b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/469 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2ba3d1243e4c818bfd05ff5aea384f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/871 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c4c520f26e42deaf556a13b96fbcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/880 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a9ea703ed94c63b7600bc46748e5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at AISE-TUDelft/CodeGPT-Multilingual were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extract embeddings......\n",
      "Time elapsed: 4693.29 seconds, Data processed:10000\n",
      "Time elapsed: 4524.14 seconds, Data processed:20000\n",
      "Time elapsed: 4881.01 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/codegpt_17669.pt\n",
      "Model vertified: CodeGPT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at AISE-TUDelft/CodeGPT-Multilingual were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extract embeddings......\n",
      "Time elapsed: 12108.80 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.70 seconds, Data predicted: 0\n",
      "Time elapsed: 222.55 seconds, Data predicted: 5000\n",
      "Time elapsed: 227.07 seconds, Data predicted: 10000\n",
      "Time elapsed: 228.05 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 60.65%\n",
      "Accuracy of Programming Task prediction: 17.17%\n"
     ]
    }
   ],
   "source": [
    "model = 'codegpt'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/codebert_30303.pt\n",
      "Model vertified: CodeBERT\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 1434.52 seconds, Data processed:10000\n",
      "Time elapsed: 1353.40 seconds, Data processed:20000\n",
      "Time elapsed: 1432.11 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/codebert_17669.pt\n",
      "Model vertified: CodeBERT\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 1442.99 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.58 seconds, Data predicted: 0\n",
      "Time elapsed: 153.82 seconds, Data predicted: 5000\n",
      "Time elapsed: 154.34 seconds, Data predicted: 10000\n",
      "Time elapsed: 155.78 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 51.37%\n",
      "Accuracy of Programming Task prediction: 10.22%\n"
     ]
    }
   ],
   "source": [
    "model = 'codebert'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/roberta_30303.pt\n",
      "Model vertified: RoBERTa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extract embeddings......\n",
      "Time elapsed: 2629.01 seconds, Data processed:10000\n",
      "Time elapsed: 2629.72 seconds, Data processed:20000\n",
      "Time elapsed: 4106.97 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/roberta_17669.pt\n",
      "Model vertified: RoBERTa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extract embeddings......\n",
      "Time elapsed: 5309.72 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.51 seconds, Data predicted: 0\n",
      "Time elapsed: 215.38 seconds, Data predicted: 5000\n",
      "Time elapsed: 215.23 seconds, Data predicted: 10000\n",
      "Time elapsed: 217.45 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 51.14%\n",
      "Accuracy of Programming Task prediction: 13.00%\n"
     ]
    }
   ],
   "source": [
    "model = 'roberta'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/epoch4_roberta_30303.pt\n",
      "Model vertified: epoch4_roberta\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 2985.74 seconds, Data processed:10000\n",
      "Time elapsed: 1970.07 seconds, Data processed:20000\n",
      "Time elapsed: 2473.00 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/epoch4_roberta_17669.pt\n",
      "Model vertified: epoch4_roberta\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 4002.98 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.61 seconds, Data predicted: 0\n",
      "Time elapsed: 222.42 seconds, Data predicted: 5000\n",
      "Time elapsed: 222.10 seconds, Data predicted: 10000\n",
      "Time elapsed: 225.15 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 59.35%\n",
      "Accuracy of Programming Task prediction: 24.85%\n"
     ]
    }
   ],
   "source": [
    "model = 'epoch4_roberta'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/epoch1_codebert_30303.pt\n",
      "Model vertified: saved model\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 2384.81 seconds, Data processed:10000\n",
      "Time elapsed: 2737.07 seconds, Data processed:20000\n",
      "Time elapsed: 3175.02 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/epoch1_codebert_17669.pt\n",
      "Model vertified: saved model\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 3160.35 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.46 seconds, Data predicted: 0\n",
      "Time elapsed: 217.80 seconds, Data predicted: 5000\n",
      "Time elapsed: 218.54 seconds, Data predicted: 10000\n",
      "Time elapsed: 223.19 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 60.71%\n",
      "Accuracy of Programming Task prediction: 23.53%\n"
     ]
    }
   ],
   "source": [
    "model = 'epoch1_codebert'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/epoch2_codebert_30303.pt\n",
      "Model vertified: saved model\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 2850.23 seconds, Data processed:10000\n",
      "Time elapsed: 2774.67 seconds, Data processed:20000\n",
      "Time elapsed: 3174.80 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/epoch2_codebert_17669.pt\n",
      "Model vertified: saved model\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 3161.32 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.43 seconds, Data predicted: 0\n",
      "Time elapsed: 223.19 seconds, Data predicted: 5000\n",
      "Time elapsed: 224.69 seconds, Data predicted: 10000\n",
      "Time elapsed: 223.41 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 61.06%\n",
      "Accuracy of Programming Task prediction: 22.10%\n"
     ]
    }
   ],
   "source": [
    "model = 'epoch2_codebert'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/epoch3_codebert_30303.pt\n",
      "Model vertified: saved model\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 1473.62 seconds, Data processed:10000\n",
      "Time elapsed: 2588.61 seconds, Data processed:20000\n",
      "Time elapsed: 3137.25 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/epoch3_codebert_17669.pt\n",
      "Model vertified: saved model\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 3180.45 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.43 seconds, Data predicted: 0\n",
      "Time elapsed: 219.28 seconds, Data predicted: 5000\n",
      "Time elapsed: 222.58 seconds, Data predicted: 10000\n",
      "Time elapsed: 221.29 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 62.93%\n",
      "Accuracy of Programming Task prediction: 22.87%\n"
     ]
    }
   ],
   "source": [
    "model = 'epoch3_codebert'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/epoch4_codebert_30303.pt\n",
      "Model vertified: saved model\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 2791.22 seconds, Data processed:10000\n",
      "Time elapsed: 2709.19 seconds, Data processed:20000\n",
      "Time elapsed: 1774.08 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/epoch4_codebert_17669.pt\n",
      "Model vertified: saved model\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 1630.40 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.32 seconds, Data predicted: 0\n",
      "Time elapsed: 156.59 seconds, Data predicted: 5000\n",
      "Time elapsed: 154.25 seconds, Data predicted: 10000\n",
      "Time elapsed: 152.78 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 63.73%\n",
      "Accuracy of Programming Task prediction: 23.75%\n"
     ]
    }
   ],
   "source": [
    "model = 'epoch4_codebert'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/epoch5_codebert_30303.pt\n",
      "Model vertified: saved model\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 2883.59 seconds, Data processed:10000\n",
      "Time elapsed: 2742.88 seconds, Data processed:20000\n",
      "Time elapsed: 3129.76 seconds, Data processed:30000\n",
      "End of extracting...Number of record: torch.Size([30303, 768])\n",
      "out/epoch5_codebert_17669.pt\n",
      "Model vertified: saved model\n",
      "Starting extract embeddings......\n",
      "Time elapsed: 3131.15 seconds, Data processed:10000\n",
      "End of extracting...Number of record: torch.Size([17669, 768])\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Original train count: 30303, test count: 17669.\n",
      "After mapping: train count: 30303, test count: 17669.\n",
      "Time elapsed: 0.77 seconds, Data predicted: 0\n",
      "Time elapsed: 216.71 seconds, Data predicted: 5000\n",
      "Time elapsed: 216.09 seconds, Data predicted: 10000\n",
      "Time elapsed: 218.19 seconds, Data predicted: 15000\n",
      "Accuracy of Programming Language prediction: 63.26%\n",
      "Accuracy of Programming Task prediction: 24.91%\n"
     ]
    }
   ],
   "source": [
    "model = 'epoch5_codebert'\n",
    "\n",
    "analyze_data(model, train_df, test_df, device, mode = 'emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
